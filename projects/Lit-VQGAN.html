<!DOCTYPE html>
<html lang="en">


<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Lit-VQGAN">

    <title>Lit-VQGAN</title>

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/charts.css/dist/charts.min.css">
    <link id="theme-style" rel="stylesheet" href="./Packages/Lit-VQGAN/css/avatarclip_main.css">
    <link id="theme-style" rel="stylesheet" href="./Packages/Lit-VQGAN/css/bulma-carousel.min.css">
    <link id="theme-style" rel="stylesheet" href="./Packages/Lit-VQGAN/css/bulma-slider.min.css">

    <!-- <script type="module" src="./assets/js/background_box.js"></script> -->
    <script type="module" src="./js/background_star.js"></script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="./Packages/Lit-VQGAN/js/bulma-carousel.min.js"></script>
    <script src="./Packages/Lit-VQGAN/js/bulma-slider.min.js"></script>
    <script src="./Packages/Lit-VQGAN/js/index.js"></script>
    <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
</head>

<body>
    
    
    <div class="wrapper">
        <!--
        <section class="section">
        
            <div class="details">
                <div align="center">
                <img class='links-cover'
                        src='./Data/banner/banner_test.png' ,height="50%" width="100%"></div>
            </div>
            
            
        </section>
        -->
        <section class="section intro-section">
            <div class="intro-container" style="text-align: center;">
                <div class="header">
                    <h3 class="papername">Terrain Scene Generation Using A Lightweight Vector Quantized Generative Adversarial Network
                    </h3>
                </div>
                <ul class="list-unstyled name-list">
                    <li><a href="" target="_blank">Yan Wang</a></li>
                    <li><a href="https://scholar.google.com/citations?user=bRWUiGIAAAAJ&hl=en&oi=ao" target="_blank">Huiyu Zhou</a></li>
                    <!-- <li><a href="https://scholar.google.com/citations?user=iPYdUpAAAAAJ&hl=en" target="_blank">Junyu Dong</a></li> -->
                    <li><a href="https://scholar.google.com/citations?user=InD0J_IAAAAJ&hl=en&oi=ao" target="_blank">Xinghui Dong</a></li>
    
                </ul>
                <ul class="list-unstyled name-list">
                    <li><a href="https://indtlab.github.io/" target="_blank">INDTLab, Ocean University of China </a></li>
                </ul>
                <!-- <ul class="list-unstyled name-list">
                    <li><a href="" target="_blank">Ocean University of China</a></li>
                </ul> -->

            </div>
            </br>
       

        <div align="center">
        <div class="container">
            <div class="columns is-multiline is-centered">
              <table>
                <tr>
                  <td style="padding:5px 5px 5px 5px;">
                      <img src='./Packages/Lit-VQGAN/Data/network/arch_small.png' height="521" width="1178" />
                  </td>
                  <!-- <td style="padding:5px 5px 5px 5px;">
                      <img src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000001.png' onmouseover="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_output2_000001.png';" onmouseout="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000001.png';"  height="256" width="256" />
                  </td>
                  <td style="padding:5px 5px 5px 5px;">
                      <img src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000002.png' onmouseover="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_output2_000002.png';" onmouseout="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000002.png';"  height="256" width="256" />
                  </td>
                  <td style="padding:5px 5px 5px 5px;">
                      <img src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000003.png' onmouseover="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_output2_000003.png';" onmouseout="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000003.png';"  height="256" width="256" />
                  </td>	 -->
                </tr>
                <!-- <tr>
                    <td style="padding:5px 5px 5px 5px;">
                        <img src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000004.png' onmouseover="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_output2_000004.png';" onmouseout="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000004.png';"  height="256" width="256" />
                    </td>
                    <td style="padding:5px 5px 5px 5px;">
                        <img src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000005.png' onmouseover="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_output2_000005.png';" onmouseout="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000005.png';"  height="256" width="256" />
                    </td>
                    <td style="padding:5px 5px 5px 5px;">
                        <img src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000006.png' onmouseover="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_output2_000006.png';" onmouseout="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000006.png';"  height="256" width="256" />
                    </td>
                    <td style="padding:5px 5px 5px 5px;">
                        <img src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000000.png' onmouseover="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_output2_000000.png';" onmouseout="this.src='./Packages/BracketFlare/Data/removal_result/Fig6_input2_000000.png';"  height="256" width="256" />
                    </td>	
                  </tr> -->
                  
              </table>
            </div>
          </div>
            <p> The architecture of the proposed Lit-VQGAN, which consists of a lightweight VQGAN built on top of two types of lightweight blocks, including
                the LFEB and the EFFB, and a lightweight super-resolution network, which is adopted using a set of Complex Attention Blocks (CABs).</p>            
            
        </div>
    </section>

        <section class='section'>
            <div class="section-title">
                Abstract
            </div>
            <div class="details" style="text-align: justify" ;>
                Natural terrain scene images play important roles in the geographical research and application. However, it is
                challenging to collect a large set of terrain scene images. Recently, great progress has been made in image generation. Although
                impressive results can be achieved,  the efficiency of the state-of-the-art methods, e.g., the Vector Quantized Generative Adversarial Network (VQGAN), 
                is still dissatisfying. The VQGAN confronts two issues, i.e., high space complexity and heavy computational demand. To efficiently fulfill the terrain scene
                generation task, we first collect a Natural Terrain Scene Data Set (NTSD), which contains 36,672 images divided into 38 classes.
                Then we propose a Lightweight VQGAN (Lit-VQGAN), which uses the fewer parameters and has the lower computational
                complexity, compared with the VQGAN. A lightweight super resolution network is further adopted, to speedily derive a high resolution image from the image that the Lit-VQGAN generates.
                The Lit-VQGAN can be trained and tested on the NTSD. To our knowledge, either the NTSD or the Lit-VQGAN has not been exploited before. Experimental results show that the  Lit-VQGAN is more efficient and effective than the VQGAN for the
                image generation task. These promising results should be due to
                the lightweight yet effective networks that we design.
            </div>
        </section>
        
        
        <section class='section links-section'>
            <div class='section-title'>
                Links
            </div>
            <div class='details links-table'>
                <table>
                    <tr>
                        <td>
                            <div class='links-container'>
                                <a href='' target="_blank"><img class='links-cover'src='./Packages/Lit-VQGAN/Data/Cover.png' alt='PDF Cover' width="140"></a>
                            </div>
                        </td>
                        <td>
                            <div class='links-container'>
                                <a href='https://github.com/INDTLab/Lit-VQGAN' target="_blank"><img class='links-cover'
                                        src='./Packages/Lit-VQGAN/Data/github.png' alt='github icon' width="160"></a>
                            </div>
                        </td>
                    </tr>
                    
                    <tr>
                        <td>
                            <a href='' target="_blank">Paper</a>
                        </td>
                        <td><a href='https://github.com/INDTLab/Lit-VQGAN' target="_blank">Code</a></td>
                        
                    </tr>
                    
                </table>
            </div>
        </section>
        


       
        <!-- <section class="section">
            <div class="section-title">
                Video
            </div>
            <div class="details">
                    <center><iframe width="1080" height="608" src="https://www.youtube.com/embed/FM8kAM13zUA" title="YouTube video player" 
                    frameborder="0" 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen></iframe></center>
            </div>
        </section> -->

        <!-- <section class="section">
            <div class="section-title">
                Dataset
            </div>
            <div class="details">
                <div align="center">
                <img class='links-cover'
                        src='./Packages/BracketFlare/Data/piechart_screenshot.png' ,height="50%" width="80%"></div>
            </div>
            <p> Visualization of typical examples and distribution of our dataset. The dataset provides different types of light sources in diverse scenes. 
                Based on light source types, we classify them into eight categories with different flare patterns.</p>
        </section> -->
        
        <section class="section">
            <div class="section-title">
                Natural Terrain Scene Data Set  (NTSD)
            </div>
            <div class="details">
                <div align="center">
                <img class='links-cover'
                        src='./Packages/Lit-VQGAN/Data/network/dataset.png' ,height="50%" width="80%"></div>
            </div>
            <div class="section-title">
                Statistics of the Data Set
            </div>
            <div class="details">
                <div align="center">
                <img class='links-cover'
                        src='./Packages/Lit-VQGAN/Data/network/statistic.png' ,height="20%" width="60%"></div>
            </div>
            <div align="center">
                <p> <b>The number of the images contained in each of the 38 classes of the Natural Terrain Scene Data Set (NTSD).</b></p>
                </div>
        </section>

        <section class="section">
            <div class="section-title">
                Experimental Results
            </div>
            <div align="center">
                <div class="container">
                    <div class="columns is-multiline is-centered">
                      <table>
                        <tr>
                          <td style="padding:5px 5px 5px 5px;">
                              <img src='./Packages/Lit-VQGAN/Data/results/TableI.png' height="80%" width="100%" />
                          </td>
                          <!-- <td style="padding:5px 5px 5px 5px;">
                            <img src='./Packages/Lit-VQGAN/Data/results/TableII.png' height="80%" width="100%" />
                        </td> -->
                        </tr>
                         
                        
                          
                      </table>
                    </div>
                  </div>
                    <p> <b>Quantitative Results of our lightweight super-resolution network and 14 baselines on five benchmark data sets.</b></p>            
                    
                </div>
            
                <div align="center">
                    <div class="container">
                        <div class="columns is-multiline is-centered">
                          <table>
                            <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/Lit-VQGAN/Data/results/rec_result.png' height="80%" width="100%" />
                                </td>
                                
                              </tr>
                              <tr> <td> <hr></td> </tr> 
                                    
                                
                                
                                
                              
                              <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/Lit-VQGAN/Data/results/generate_result.png' height="80%" width="100%" />
                                </td>
                              </tr>
                              <!-- <tr> <td> <hr></td> </tr> -->
                              <!-- <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/Lit-VQGAN/Data/results/EUVP_half.png' height="80%" width="100%" />
                                </td>
                              </tr> -->
                              <tr> <td> <hr></td> </tr>
                            <!-- <tr>
                              <td style="padding:5px 5px 5px 5px;">
                                  <img src='./Packages/Lit-VQGAN/Data/results/C60_half.png' height="80%" width="100%" />
                              </td>
                            </tr> -->
                            
                            <!-- <tr>
                                <td style="padding:5px 5px 5px 5px;">
                                    <img src='./Packages/Lit-VQGAN/Data/results/RUIE_half.png' height="80%" width="100%" />
                                </td>
                              </tr> -->
                            
            
                             
                            
                              
                          </table>
                          <p> <b> The natural terrain scene image reconstruction results derived using three VQGAN networks. And Examples of the high-resolution images generated by our method.</b> </p>     

                        </div>
                      </div>
                               
                        
                    </div>
        </section>
         <!-- <section class='section'>
            <div class='section-title'>
                Citation
            </div>
            
                <pre>
                    <code>
    @ARTICLE{10336777,
    author={Qi, Hao and Zhou, Huiyu and Dong, Junyu and Dong, Xinghui},
    journal={IEEE Transactions on Geoscience and Remote Sensing}, 
    title={Deep Color-Corrected Multi-scale Retinex Network for Underwater Image Enhancement}, 
    year={2023},
    doi={10.1109/TGRS.2023.3338611}}
                    </code>
                  </pre>
                  

        </section> -->
        

        <section>
    
<!--             <p>We referred to the project page of <a href="https://ykdai.github.io/projects/BracketFlare">BracketFlare</a> when creating this
                project page.</p> -->
            <!-- <p> This project is licensed under <a
                href="https://github.com/ykdai/BracketFlare/blob/main/LICENSE">NTU S-Lab License 1.0</a>. Redistribution and use should follow this license.</p> -->
        </section>

    </div>


</body>

</html>
